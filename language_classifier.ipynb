{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        pt\n",
      "1        bg\n",
      "2        zh\n",
      "3        th\n",
      "4        ru\n",
      "         ..\n",
      "69995    ja\n",
      "69996    el\n",
      "69997    ur\n",
      "69998    es\n",
      "69999    hi\n",
      "Name: labels, Length: 70000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load data from a CSV file\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(train_data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abreviations_to_full_label_names = {\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"ar\": \"Arabic\",\n",
    "    \"ru\": \"Russian\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"bg\": \"Bulgarian\",\n",
    "    \"de\": \"German\",\n",
    "    \"el\": \"Greek\",\n",
    "    \"en\": \"English\",\n",
    "    \"fr\": \"French\",\n",
    "    \"hi\": \"Hindi\",\n",
    "    \"ja\": \"Japanese\",\n",
    "    \"pl\": \"Polish\",\n",
    "    \"pt\": \"Portuguese\",\n",
    "    \"sw\": \"Swahili\",\n",
    "    \"th\": \"Thai\",\n",
    "    \"ur\": \"Urdu\",\n",
    "    \"vi\": \"Vietnamese\",\n",
    "    \"zh\": \"Chinese\"\n",
    "}\n",
    "test_data[\"labels\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          labels                                               text\n",
      "0          Dutch                    Een man zingt en speelt gitaar.\n",
      "1          Dutch  De technologisch geplaatste Nasdaq Composite I...\n",
      "2        Spanish  Es muy resistente la parte trasera rígida y lo...\n",
      "3        Italian  \"In tanti modi diversi, l'abilità artistica de...\n",
      "4         Arabic  منحدر يواجه العديد من النقاشات المتجهه إزاء ال...\n",
      "...          ...                                                ...\n",
      "9995     Chinese                               史料很充分，对岸的很多观点与大陆迥异啊。\n",
      "9996     Turkish  Örneğin, teşhis Yunanca bir kelimeden alındı (...\n",
      "9997  Vietnamese  Nếu lite/light chỉ đơn giản là mô tả một đặc t...\n",
      "9998   Bulgarian  Например, една щатска столица, която посетихме...\n",
      "9999      Polish                   Mam dla ciebie kilka propozycji:\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "full_labels = []\n",
    "for label_abr in test_data[\"labels\"]:\n",
    "    full_labels.append(abreviations_to_full_label_names[label_abr])\n",
    "test_data[\"labels\"] = full_labels\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           labels                                               text\n",
      "0      Portuguese  os chefes de defesa da estónia, letónia, lituâ...\n",
      "1       Bulgarian  размерът на хоризонталната мрежа може да бъде ...\n",
      "2         Chinese  很好，以前从不去评价，不知道浪费了多少积分，现在知道积分可以换钱，就要好好评价了，后来我就把...\n",
      "3            Thai  สำหรับ ของเก่า ที่ จริงจัง ลอง   honeychurch  ...\n",
      "4         Russian                             Он увеличил давление .\n",
      "...           ...                                                ...\n",
      "69995    Japanese  本格的なゲーミングヘッドホンでした。 今まで使ってた1万円するパナソニックのヘッドホンは何だ...\n",
      "69996       Greek  Ναι , ξέρω ένα που είναι ακόμα έτσι , αλλά αυτ...\n",
      "69997        Urdu  اور مجھے اس ملک کے بارے میں معلوم نہیں ہے کہ گ...\n",
      "69998     Spanish  Se me rompió uno al sacarlo del cargador. Cali...\n",
      "69999       Hindi  कोसोवो कथा का विवरण जिसमें स ् थानीय राष ् ट ्...\n",
      "\n",
      "[70000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "full_labels = []\n",
    "for label_abr in train_data[\"labels\"]:\n",
    "    full_labels.append(abreviations_to_full_label_names[label_abr])\n",
    "train_data[\"labels\"] = full_labels\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Portuguese\n",
      "1         Bulgarian\n",
      "2           Chinese\n",
      "3              Thai\n",
      "4           Russian\n",
      "            ...    \n",
      "69995      Japanese\n",
      "69996         Greek\n",
      "69997          Urdu\n",
      "69998       Spanish\n",
      "69999         Hindi\n",
      "Name: labels, Length: 70000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data[\"text\"]\n",
    "y_train = train_data[\"labels\"]\n",
    "\n",
    "X_test = test_data[\"text\"]\n",
    "y_test = test_data[\"labels\"]\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer() #Found out about count vectorizer through ChatGPT. Count vectorizer converts text into a series of vectors that can be processed\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier.fit(X_train_counts, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9214\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language(sample_text):\n",
    "    input_text_counts = vectorizer.transform([sample_text])\n",
    "    predicted_language = classifier.predict(input_text_counts)\n",
    "    return predicted_language[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish\n"
     ]
    }
   ],
   "source": [
    "text_sample = input(\"Please enter a word/phrase\")\n",
    "\n",
    "text_sample_predict = predict_language(text_sample)\n",
    "print(text_sample_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
